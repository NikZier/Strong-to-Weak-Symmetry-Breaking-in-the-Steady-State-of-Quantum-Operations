{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd078ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))\n",
    "import matplotlib.pyplot as plt\n",
    "np.set_printoptions(precision=5, suppress=True, linewidth=100)\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "import tenpy\n",
    "tenpy.tools.misc.setup_logging(to_stdout=\"INFO\")\n",
    "from src.MPO_functions import MPS_drop_charge, double_to_mpo, mpo_product, mpo_trace, truncate_mpo\n",
    "import gc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "torch.set_default_dtype(torch.float64)\n",
    "import random\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08de109c",
   "metadata": {},
   "source": [
    "### Calculate Renyi-m correlators for m=2,4,6,8 from ground state data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dee0a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load ground state MPS from file\n",
    "L=8\n",
    "with open(\"..\\\\data\\\\groundstates_Z2_L\"+str(L)+\".pkl\", \"rb\") as f:\n",
    "    states = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e38cfa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999996093742739\n",
      "0.999998437495879\n",
      "0.9999964843648129\n",
      "0.9999937499835185\n",
      "0\n",
      "0.9971196007153456\n",
      "0.988367804296063\n",
      "0.9736914228619121\n",
      "0.9531910875069985\n",
      "1\n",
      "0.988027805974277\n",
      "0.9503800622071364\n",
      "0.886538679745139\n",
      "0.7985986756636244\n",
      "2\n",
      "0.9706733256285679\n",
      "0.8733922866029972\n",
      "0.7097776507871467\n",
      "0.512000563326728\n",
      "3\n",
      "0.9401382818569178\n",
      "0.7319797818747972\n",
      "0.4386315980871694\n",
      "0.21585061233731456\n",
      "4\n",
      "0.8857807692605153\n",
      "0.5122859125934166\n",
      "0.19113011643763114\n",
      "0.063660330907945\n",
      "5\n",
      "0.7910287325435014\n",
      "0.2779269535982813\n",
      "0.06238538940319851\n",
      "0.014566562665439372\n",
      "6\n",
      "0.6486918518772847\n",
      "0.12108440198144152\n",
      "0.01700916220474426\n",
      "0.002723833764337117\n",
      "7\n",
      "0.48492161861941646\n",
      "0.04769975112385166\n",
      "0.004296342816391706\n",
      "0.00045541963544054777\n",
      "8\n",
      "0.34115940241822595\n",
      "0.018850165451298702\n",
      "0.0011054164687673194\n",
      "7.675165960893069e-05\n",
      "9\n",
      "0.2355134405658366\n",
      "0.00787272724279988\n",
      "0.00030718732027346573\n",
      "1.4165499142624518e-05\n",
      "10\n",
      "0.16380185338838904\n",
      "0.003526175719253671\n",
      "9.404809627502595e-05\n",
      "2.954105725519494e-06\n",
      "11\n",
      "0.11607458529751476\n",
      "0.0016902263463504006\n",
      "3.16798402115869e-05\n",
      "6.969390723610443e-07\n",
      "12\n",
      "0.08406247859823004\n",
      "0.0008607933272075278\n",
      "1.163603560028443e-05\n",
      "1.8410773670749985e-07\n",
      "13\n",
      "0.06219443072042167\n",
      "0.00046210785712336947\n",
      "4.61195053241521e-06\n",
      "5.3755196320925944e-08\n",
      "14\n",
      "0.04693425239156018\n",
      "0.00025965461656758773\n",
      "1.9534505936262032e-06\n",
      "1.7133396473825608e-08\n",
      "15\n",
      "0.036056983763770305\n",
      "0.0001517888604615509\n",
      "8.767978043558456e-07\n",
      "5.896528051467744e-09\n",
      "16\n",
      "0.028147747212860435\n",
      "9.185297833079161e-05\n",
      "4.1407641903340157e-07\n",
      "2.1708668357105048e-09\n",
      "17\n",
      "0.022290556618949384\n",
      "5.729837117402731e-05\n",
      "2.0452412325606132e-07\n",
      "8.482745687128004e-10\n",
      "18\n",
      "0.017880352763769786\n",
      "3.6717510067793186e-05\n",
      "1.0512431048864526e-07\n",
      "3.4947882725161484e-10\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "L=8 #system size\n",
    "\n",
    "R2=[]\n",
    "R4=[]\n",
    "R6=[]\n",
    "R8=[]\n",
    "for i,psi in enumerate(states):\n",
    "    psi=states[i].copy()\n",
    "    phi=psi.copy()\n",
    "    phi.apply_local_term([('Sigmax',int((L/4-1)*2)),('Sigmax',int((L/4-1)*2+1)),('Sigmax',int(L-L/4-1)*2),('Sigmax',int(L-L/4-1)*2+1)])\n",
    "    rho=double_to_mpo(MPS_drop_charge(psi),L)\n",
    "    sig=double_to_mpo(MPS_drop_charge(phi),L)\n",
    "    rho2=mpo_product(rho,rho,chi_max=40,eps=10e-20)\n",
    "    tau=mpo_product(rho,sig,chi_max=40,eps=10e-20)\n",
    "    tau2=mpo_product(tau,tau,chi_max=40,eps=10e-25)\n",
    "    rho4=mpo_product(rho2,rho2,chi_max=40,eps=10e-25)\n",
    "    R2.append(mpo_trace(tau)/mpo_trace(rho2))\n",
    "    print(R2[i])\n",
    "    tau3=mpo_product(tau2,tau,chi_max=40,eps=10e-25)\n",
    "    rho6=mpo_product(rho4,rho2,chi_max=40,eps=10e-25)\n",
    "    R4.append(mpo_trace(tau2)/mpo_trace(rho4))\n",
    "    print(R4[i])\n",
    "    R6.append(mpo_trace(tau3)/mpo_trace(rho6))\n",
    "    print(R6[i])\n",
    "    gc.collect()\n",
    "    tau4=mpo_product(tau2,tau2,chi_max=40,eps=10e-30)\n",
    "    rho8=mpo_product(rho4,rho4,chi_max=40,eps=10e-30)\n",
    "    R8.append(mpo_trace(tau4)/mpo_trace(rho8))\n",
    "    print(R8[i])\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd1dcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#write correlators to file\n",
    "field_names=[\"L\",\"J\",\"U\",\"s\"]\n",
    "file_name=r\"..\\\\data\\\\correlators_Z2\\\\Ising_DMRG_L\"+str(L)+\".csv\"\n",
    "\n",
    "data = {\n",
    "\"R2\": R2,\n",
    "\"R4\": R4,\n",
    "\"R6\": R6,\n",
    "\"R8\": R8,\n",
    "\"p\": ps,\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(file_name, mode='a', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a73b70",
   "metadata": {},
   "source": [
    "### Train neural network to learn fidelities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d483d497",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b040cd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_ising(L):\n",
    "    \"\"\"Load one Ising CSV file and return (X, Y).\"\"\"\n",
    "    path = os.path.join(\"..\", \"data\", \"correlators_Z2\", f\"Ising_exact_L{L}.csv\")\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    Y = df[\"fid\"].to_numpy()\n",
    "    X = df[[\"R2\", \"R4\", \"R6\", \"R8\"]].to_numpy()\n",
    "    X = np.c_[X, L * np.ones(X.shape[0]), np.linspace(0, 2, X.shape[0])]\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "sizes = [4, 6, 8, 10, 12, 14,16,18]  \n",
    "data = {L: load_ising(L) for L in sizes}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e08c4536",
   "metadata": {},
   "outputs": [],
   "source": [
    "X4, Y4 = data[4]\n",
    "X6, Y6 = data[6]\n",
    "X8, Y8 = data[8]\n",
    "X10, Y10 = data[10]\n",
    "X12, Y12 = data[12]\n",
    "X14, Y14 = data[14]\n",
    "X16, Y16 = data[16]\n",
    "X18, Y18 = data[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c267b2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generates analytically known data. at p=\\infty we now that all correlators vanish and at p=0, all correlators are equal to 1\n",
    "physicsX_p0 = np.ones((64,6))\n",
    "physicsX_p0[:,4]=np.arange(1,65)\n",
    "physicsX_p0[:,5]=0\n",
    "physicsY_p0=np.ones(64)\n",
    "\n",
    "physicsX_pinf = np.zeros((64,6))\n",
    "physicsX_pinf[:,4]=np.arange(1,65)\n",
    "physicsX_pinf[:,5]=1e6\n",
    "physicsY_pinf=np.zeros(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77f11d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.concatenate((X4,X6,X8,X10,X12,X14,X16,X18,physicsX_p0,physicsX_pinf))\n",
    "Y=np.concatenate((Y4,Y6,Y8,Y10,Y12,Y14,Y16,Y18,physicsY_p0,physicsY_pinf))\n",
    "\n",
    "# Split into train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "012ac62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float64)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float64).view(-1, 1)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float64)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float64).view(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1185f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(6, 32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(16, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22673d7",
   "metadata": {},
   "source": [
    "### Import DMRG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1aa451d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DMRG32=pd.read_csv(r\"..\\\\data\\\\correlators_Z2\\\\Ising_DMRG_L32.csv\")\n",
    "DMRG32_X=DMRG32[[\"R2\",\"R4\",\"R6\",\"R8\"]].to_numpy()\n",
    "DMRG32_X=np.c_[DMRG32_X,32*np.ones(DMRG32_X.shape[0]),DMRG32[\"p\"].to_numpy()/8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b86f88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DMRG64=pd.read_csv(r\"..\\\\data\\\\correlators_Z2\\\\Ising_DMRG_L64.csv\")\n",
    "DMRG64_X=DMRG64[[\"R2\",\"R4\",\"R6\",\"R8\"]].to_numpy()\n",
    "DMRG64_X=np.c_[DMRG64_X,64*np.ones(DMRG64_X.shape[0]),DMRG64[\"p\"].to_numpy()/8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1e959dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_prediction_tensor_32 = torch.tensor(DMRG32_X, dtype=torch.float64)\n",
    "X_prediction_tensor_64 = torch.tensor(DMRG64_X, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "938e88a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 10/1000, Loss: 0.1404912419730552\n",
      "Epoch 20/1000, Loss: 0.12296228008064772\n",
      "Epoch 30/1000, Loss: 0.11676245006203115\n",
      "Epoch 40/1000, Loss: 0.11339198471491671\n",
      "Epoch 50/1000, Loss: 0.04140046367416482\n",
      "Epoch 60/1000, Loss: 0.019432311219036543\n",
      "Epoch 70/1000, Loss: 0.0015879936075983202\n",
      "Epoch 80/1000, Loss: 0.0016567255958645022\n",
      "Epoch 90/1000, Loss: 0.0010787908625332575\n",
      "Epoch 100/1000, Loss: 0.0004958456608995839\n",
      "Epoch 110/1000, Loss: 0.00018037828370284518\n",
      "Epoch 120/1000, Loss: 0.00010240112663606672\n",
      "Epoch 130/1000, Loss: 7.402463172161855e-05\n",
      "Epoch 140/1000, Loss: 5.8026027546376147e-05\n",
      "Epoch 150/1000, Loss: 5.075932011987709e-05\n",
      "Epoch 160/1000, Loss: 4.603067555971158e-05\n",
      "Epoch 170/1000, Loss: 4.27855655271674e-05\n",
      "Epoch 180/1000, Loss: 3.963607453197686e-05\n",
      "Epoch 190/1000, Loss: 3.718633638318594e-05\n",
      "Epoch 200/1000, Loss: 3.5132405871797476e-05\n",
      "Epoch 210/1000, Loss: 3.338583414438988e-05\n",
      "Epoch 220/1000, Loss: 3.369185837287477e-05\n",
      "Epoch 230/1000, Loss: 8.08910808103621e-05\n",
      "Epoch 240/1000, Loss: 5.1663961787648753e-05\n",
      "Epoch 250/1000, Loss: 4.2639645114188926e-05\n",
      "Epoch 260/1000, Loss: 3.798789680188569e-05\n",
      "Epoch 270/1000, Loss: 3.029913813377666e-05\n",
      "Epoch 280/1000, Loss: 2.825133339813622e-05\n",
      "Epoch 290/1000, Loss: 2.888719837953727e-05\n",
      "Epoch 300/1000, Loss: 6.706335078153235e-05\n",
      "Epoch 310/1000, Loss: 5.259436653609169e-05\n",
      "Epoch 320/1000, Loss: 2.9420452262135677e-05\n",
      "Epoch 330/1000, Loss: 4.1460334447537366e-05\n",
      "Epoch 340/1000, Loss: 2.4449794524811888e-05\n",
      "Epoch 350/1000, Loss: 2.4056565021052655e-05\n",
      "Epoch 360/1000, Loss: 2.4608213202987822e-05\n",
      "Epoch 370/1000, Loss: 2.2771663780333344e-05\n",
      "Epoch 380/1000, Loss: 3.546928751581314e-05\n",
      "Epoch 390/1000, Loss: 3.3063538537667875e-05\n",
      "Epoch 400/1000, Loss: 7.629734073316937e-05\n",
      "Epoch 410/1000, Loss: 5.859457397738755e-05\n",
      "Epoch 420/1000, Loss: 2.2490159897071366e-05\n",
      "Epoch 430/1000, Loss: 2.0745391337720735e-05\n",
      "Epoch 440/1000, Loss: 1.9794626015761697e-05\n",
      "Epoch 450/1000, Loss: 1.9593366300621817e-05\n",
      "Epoch 460/1000, Loss: 1.8617542893197995e-05\n",
      "Epoch 470/1000, Loss: 1.8053065979126095e-05\n",
      "Epoch 480/1000, Loss: 1.748923776804322e-05\n",
      "Epoch 490/1000, Loss: 1.7007295253803192e-05\n",
      "Epoch 500/1000, Loss: 1.6567551024994736e-05\n",
      "Epoch 510/1000, Loss: 1.8748255879793663e-05\n",
      "Epoch 520/1000, Loss: 0.0004871506193478729\n",
      "Epoch 530/1000, Loss: 0.0001438159241722747\n",
      "Epoch 540/1000, Loss: 5.8608170226838246e-05\n",
      "Epoch 550/1000, Loss: 2.416641588355448e-05\n",
      "Epoch 560/1000, Loss: 1.8690121343178007e-05\n",
      "Epoch 570/1000, Loss: 1.7497623023228503e-05\n",
      "Epoch 580/1000, Loss: 1.4271049559198338e-05\n",
      "Epoch 590/1000, Loss: 1.3825768904168597e-05\n",
      "Epoch 600/1000, Loss: 1.305668830178671e-05\n",
      "Epoch 610/1000, Loss: 1.26903557053179e-05\n",
      "Epoch 620/1000, Loss: 1.237939571829568e-05\n",
      "Epoch 630/1000, Loss: 1.2032778199184164e-05\n",
      "Epoch 640/1000, Loss: 1.2198779187307365e-05\n",
      "Epoch 650/1000, Loss: 8.833798612894821e-05\n",
      "Epoch 660/1000, Loss: 0.00015908629273505103\n",
      "Epoch 670/1000, Loss: 5.580414456288254e-05\n",
      "Epoch 680/1000, Loss: 2.879900611839517e-05\n",
      "Epoch 690/1000, Loss: 1.4315106414963761e-05\n",
      "Epoch 700/1000, Loss: 1.1018199966648929e-05\n",
      "Epoch 710/1000, Loss: 1.1276817316123367e-05\n",
      "Epoch 720/1000, Loss: 1.0359663296176046e-05\n",
      "Epoch 730/1000, Loss: 9.850285498214946e-06\n",
      "Epoch 740/1000, Loss: 9.58844777399435e-06\n",
      "Epoch 750/1000, Loss: 9.262293084371126e-06\n",
      "Epoch 760/1000, Loss: 9.140221512254078e-06\n",
      "Epoch 770/1000, Loss: 1.3557977308551609e-05\n",
      "Epoch 780/1000, Loss: 0.0003544527499228658\n",
      "Epoch 790/1000, Loss: 3.4161602128798794e-05\n",
      "Epoch 800/1000, Loss: 1.4703796929347594e-05\n",
      "Epoch 810/1000, Loss: 9.087959456900171e-06\n",
      "Epoch 820/1000, Loss: 1.185399274789062e-05\n",
      "Epoch 830/1000, Loss: 8.97516412249951e-06\n",
      "Epoch 840/1000, Loss: 8.579982932435668e-06\n",
      "Epoch 850/1000, Loss: 7.801689098359082e-06\n",
      "Epoch 860/1000, Loss: 7.555687329224396e-06\n",
      "Epoch 870/1000, Loss: 7.415596059315207e-06\n",
      "Epoch 880/1000, Loss: 7.311058872230301e-06\n",
      "Epoch 890/1000, Loss: 8.962863880535027e-06\n",
      "Epoch 900/1000, Loss: 0.00013652080598491368\n",
      "Epoch 910/1000, Loss: 0.00011251282456327841\n",
      "Epoch 920/1000, Loss: 1.87209583984097e-05\n",
      "Epoch 930/1000, Loss: 9.526736057509356e-06\n",
      "Epoch 940/1000, Loss: 1.1972650799287727e-05\n",
      "Epoch 950/1000, Loss: 7.122780168349903e-06\n",
      "Epoch 960/1000, Loss: 6.390137440233737e-06\n",
      "Epoch 970/1000, Loss: 6.316818374040195e-06\n",
      "Epoch 980/1000, Loss: 6.989637414821436e-06\n",
      "Epoch 990/1000, Loss: 5.81444639166748e-06\n",
      "Epoch 1000/1000, Loss: 5.678423075846328e-06\n",
      "Maximum absolute weight: 1.0211955828234265\n",
      "\n",
      "---------- finished run ----------\n",
      "1\n",
      "Epoch 10/1000, Loss: 0.1826457338361053\n",
      "Epoch 20/1000, Loss: 0.12680091061037105\n",
      "Epoch 30/1000, Loss: 0.1292146809459195\n",
      "Epoch 40/1000, Loss: 0.11914652528396363\n",
      "Epoch 50/1000, Loss: 0.11324392895762625\n",
      "Epoch 60/1000, Loss: 0.10107922678100006\n",
      "Epoch 70/1000, Loss: 0.07887002917683388\n",
      "Epoch 80/1000, Loss: 0.0043371092424620275\n",
      "Epoch 90/1000, Loss: 0.0015407535509576165\n",
      "Epoch 100/1000, Loss: 0.0010032421647571163\n",
      "Epoch 110/1000, Loss: 0.0006921059399624443\n",
      "Epoch 120/1000, Loss: 0.00030981204225563277\n",
      "Epoch 130/1000, Loss: 0.00033993778871485564\n",
      "Epoch 140/1000, Loss: 0.00016437678616327433\n",
      "Epoch 150/1000, Loss: 0.00012127812971197198\n",
      "Epoch 160/1000, Loss: 0.00019381705997817175\n",
      "Epoch 170/1000, Loss: 0.00023217841399582407\n",
      "Epoch 180/1000, Loss: 0.00014445998110050517\n",
      "Epoch 190/1000, Loss: 8.88101102739371e-05\n",
      "Epoch 200/1000, Loss: 8.054625570114367e-05\n",
      "Epoch 210/1000, Loss: 6.173102316326309e-05\n",
      "Epoch 220/1000, Loss: 0.000512127108832251\n",
      "Epoch 230/1000, Loss: 0.00016283588684826373\n",
      "Epoch 240/1000, Loss: 6.02423839365693e-05\n",
      "Epoch 250/1000, Loss: 6.434493479076185e-05\n",
      "Epoch 260/1000, Loss: 5.05320125841506e-05\n",
      "Epoch 270/1000, Loss: 5.6863417960066345e-05\n",
      "Epoch 280/1000, Loss: 0.00021308906386121514\n",
      "Epoch 290/1000, Loss: 0.00014667971570327273\n",
      "Epoch 300/1000, Loss: 4.7948094754302666e-05\n",
      "Epoch 310/1000, Loss: 4.089296433469333e-05\n",
      "Epoch 320/1000, Loss: 5.5771617811601464e-05\n",
      "Epoch 330/1000, Loss: 6.531347739394751e-05\n",
      "Epoch 340/1000, Loss: 0.00015547929206882462\n",
      "Epoch 350/1000, Loss: 4.0204019239897825e-05\n",
      "Epoch 360/1000, Loss: 3.411833759279713e-05\n",
      "Epoch 370/1000, Loss: 4.0551074682299175e-05\n",
      "Epoch 380/1000, Loss: 3.1175565778373084e-05\n",
      "Epoch 390/1000, Loss: 4.650276857814597e-05\n",
      "Epoch 400/1000, Loss: 3.9034258274995404e-05\n",
      "Epoch 410/1000, Loss: 5.6286237532115846e-05\n",
      "Epoch 420/1000, Loss: 4.4858950888612394e-05\n",
      "Epoch 430/1000, Loss: 3.452326494398714e-05\n",
      "Epoch 440/1000, Loss: 2.6101424733899726e-05\n",
      "Epoch 450/1000, Loss: 2.7521556608629714e-05\n",
      "Epoch 460/1000, Loss: 2.4895002848131922e-05\n",
      "Epoch 470/1000, Loss: 2.3658245170623135e-05\n",
      "Epoch 480/1000, Loss: 2.2399751480932027e-05\n",
      "Epoch 490/1000, Loss: 4.217905886810217e-05\n",
      "Epoch 500/1000, Loss: 4.3563903576084387e-05\n",
      "Epoch 510/1000, Loss: 6.00896467596086e-05\n",
      "Epoch 520/1000, Loss: 4.752117879245498e-05\n",
      "Epoch 530/1000, Loss: 3.149092494817172e-05\n",
      "Epoch 540/1000, Loss: 2.0166739239436066e-05\n",
      "Epoch 550/1000, Loss: 2.1242388962983385e-05\n",
      "Epoch 560/1000, Loss: 1.9661334798137304e-05\n",
      "Epoch 570/1000, Loss: 1.9418285852098142e-05\n",
      "Epoch 580/1000, Loss: 4.2753560939166456e-05\n",
      "Epoch 590/1000, Loss: 7.330202393517502e-05\n",
      "Epoch 600/1000, Loss: 5.7465637089304895e-05\n",
      "Epoch 610/1000, Loss: 2.6312788887938364e-05\n",
      "Epoch 620/1000, Loss: 1.8066944939072643e-05\n",
      "Epoch 630/1000, Loss: 1.8227817668070296e-05\n",
      "Epoch 640/1000, Loss: 1.620265547763568e-05\n",
      "Epoch 650/1000, Loss: 1.8438936787397422e-05\n",
      "Epoch 660/1000, Loss: 0.00016456353739722901\n",
      "Epoch 670/1000, Loss: 0.00011555585391256067\n",
      "Epoch 680/1000, Loss: 2.83050814976526e-05\n",
      "Epoch 690/1000, Loss: 2.4176387901175397e-05\n",
      "Epoch 700/1000, Loss: 2.129061870423449e-05\n",
      "Epoch 710/1000, Loss: 1.7928068544907318e-05\n",
      "Epoch 720/1000, Loss: 1.4322326494881433e-05\n",
      "Epoch 730/1000, Loss: 1.570407260294926e-05\n",
      "Epoch 740/1000, Loss: 0.0001858565809964102\n",
      "Epoch 750/1000, Loss: 0.00014830226763974539\n",
      "Epoch 760/1000, Loss: 3.133647347580771e-05\n",
      "Epoch 770/1000, Loss: 1.6816516050736275e-05\n",
      "Epoch 780/1000, Loss: 2.0688500841727228e-05\n",
      "Epoch 790/1000, Loss: 1.5361604729425126e-05\n",
      "Epoch 800/1000, Loss: 1.366782446277258e-05\n",
      "Epoch 810/1000, Loss: 1.4133535063907347e-05\n",
      "Epoch 820/1000, Loss: 1.541518129952132e-05\n",
      "Epoch 830/1000, Loss: 0.00011297432239476886\n",
      "Epoch 840/1000, Loss: 5.764046102089827e-05\n",
      "Epoch 850/1000, Loss: 4.96645284039578e-05\n",
      "Epoch 860/1000, Loss: 1.7503872909317808e-05\n",
      "Epoch 870/1000, Loss: 1.3717300586400045e-05\n",
      "Epoch 880/1000, Loss: 1.6433957774905786e-05\n",
      "Epoch 890/1000, Loss: 1.2558545268343714e-05\n",
      "Epoch 900/1000, Loss: 1.43123098329697e-05\n",
      "Epoch 910/1000, Loss: 0.00020669693533140396\n",
      "Epoch 920/1000, Loss: 0.00012033134381314204\n",
      "Epoch 930/1000, Loss: 1.8303193196973076e-05\n",
      "Epoch 940/1000, Loss: 2.6334772319357477e-05\n",
      "Epoch 950/1000, Loss: 1.2295749640898012e-05\n",
      "Epoch 960/1000, Loss: 1.2804467394430613e-05\n",
      "Epoch 970/1000, Loss: 1.1468048834291143e-05\n",
      "Epoch 980/1000, Loss: 1.2663858338796966e-05\n",
      "Epoch 990/1000, Loss: 1.665617278162498e-05\n",
      "Epoch 1000/1000, Loss: 0.00020722912119680904\n",
      "Maximum absolute weight: 0.5833609002417072\n",
      "\n",
      "---------- finished run ----------\n",
      "2\n",
      "Epoch 10/1000, Loss: 0.12276960415874728\n",
      "Epoch 20/1000, Loss: 0.11877036196949985\n",
      "Epoch 30/1000, Loss: 0.11253113024414832\n",
      "Epoch 40/1000, Loss: 0.10896733004790476\n",
      "Epoch 50/1000, Loss: 0.10270213706309735\n",
      "Epoch 60/1000, Loss: 0.08836318188051938\n",
      "Epoch 70/1000, Loss: 0.007190363040933532\n",
      "Epoch 80/1000, Loss: 0.003338553072029136\n",
      "Epoch 90/1000, Loss: 0.001787836316068932\n",
      "Epoch 100/1000, Loss: 0.0007557071969313652\n",
      "Epoch 110/1000, Loss: 0.06369413011654067\n",
      "Epoch 120/1000, Loss: 0.06353471740643948\n",
      "Epoch 130/1000, Loss: 0.00013924662593185478\n",
      "Epoch 140/1000, Loss: 0.06345670675092477\n",
      "Epoch 150/1000, Loss: 0.06343999777967321\n",
      "Epoch 160/1000, Loss: 0.06342156288699093\n",
      "Epoch 170/1000, Loss: 0.06341092664055879\n",
      "Epoch 180/1000, Loss: 0.06340261739766889\n",
      "Epoch 190/1000, Loss: 0.06339551469312667\n",
      "Epoch 200/1000, Loss: 0.06363072802991607\n",
      "Epoch 210/1000, Loss: 0.06342671807106164\n",
      "Epoch 220/1000, Loss: 0.06342661621383597\n",
      "Epoch 230/1000, Loss: 0.06338092118087825\n",
      "Epoch 240/1000, Loss: 0.06337611155793414\n",
      "Epoch 250/1000, Loss: 0.06337332328866244\n",
      "Epoch 260/1000, Loss: 0.06337176209129218\n",
      "Epoch 270/1000, Loss: 0.0633688203436146\n",
      "Epoch 280/1000, Loss: 0.06336697117781626\n",
      "Epoch 290/1000, Loss: 0.06336526921862885\n",
      "Epoch 300/1000, Loss: 0.06339401050698458\n",
      "Epoch 310/1000, Loss: 0.063431986081508\n",
      "Epoch 320/1000, Loss: 0.06338692122495886\n",
      "Epoch 330/1000, Loss: 0.06337922426131673\n",
      "Epoch 340/1000, Loss: 0.06336778009931042\n",
      "Epoch 350/1000, Loss: 0.06336101776789912\n",
      "Epoch 360/1000, Loss: 0.06335779887024952\n",
      "Epoch 370/1000, Loss: 0.06335763086567447\n",
      "Epoch 380/1000, Loss: 0.06335659788139078\n",
      "Epoch 390/1000, Loss: 0.06335611628551643\n",
      "Epoch 400/1000, Loss: 0.06335755755930228\n",
      "Epoch 410/1000, Loss: 0.06363097697009973\n",
      "Epoch 420/1000, Loss: 0.06335682620351954\n",
      "Epoch 430/1000, Loss: 0.06336283191048125\n",
      "Epoch 440/1000, Loss: 0.06336291690547108\n",
      "Epoch 450/1000, Loss: 0.06335804415744281\n",
      "Epoch 460/1000, Loss: 0.06335380822959585\n",
      "Epoch 470/1000, Loss: 0.06335275654322807\n",
      "Epoch 480/1000, Loss: 0.06335280995829301\n",
      "Epoch 490/1000, Loss: 0.06335217995394919\n",
      "Epoch 500/1000, Loss: 0.06335543841574823\n",
      "Epoch 510/1000, Loss: 0.06360358603360682\n",
      "Epoch 520/1000, Loss: 0.06337417257448891\n",
      "Epoch 530/1000, Loss: 0.06337819294718067\n",
      "Epoch 540/1000, Loss: 0.06335535880976546\n",
      "Epoch 550/1000, Loss: 0.06335328688054144\n",
      "Epoch 560/1000, Loss: 0.06335061459841149\n",
      "Epoch 570/1000, Loss: 0.06335041954440902\n",
      "Epoch 580/1000, Loss: 0.06335011570273405\n",
      "Epoch 590/1000, Loss: 0.06334981222631174\n",
      "Epoch 600/1000, Loss: 0.06335155029843141\n",
      "Epoch 610/1000, Loss: 0.06361358485784654\n",
      "Epoch 620/1000, Loss: 0.06338885404441794\n",
      "Epoch 630/1000, Loss: 0.06337613853020871\n",
      "Epoch 640/1000, Loss: 0.06336201124673294\n",
      "Epoch 650/1000, Loss: 0.06335273373016331\n",
      "Epoch 660/1000, Loss: 0.06334928850475176\n",
      "Epoch 670/1000, Loss: 0.06334907346482287\n",
      "Epoch 680/1000, Loss: 0.06334882858562041\n",
      "Epoch 690/1000, Loss: 0.06334848120142648\n",
      "Epoch 700/1000, Loss: 0.06334832103671034\n",
      "Epoch 710/1000, Loss: 0.06334814778415308\n",
      "Epoch 720/1000, Loss: 0.06334852805627388\n",
      "Epoch 730/1000, Loss: 0.06346031961769855\n",
      "Epoch 740/1000, Loss: 0.06348971359834867\n",
      "Epoch 750/1000, Loss: 0.06338451544283209\n",
      "Epoch 760/1000, Loss: 0.06336144729379081\n",
      "Epoch 770/1000, Loss: 0.06335051715460821\n",
      "Epoch 780/1000, Loss: 0.06334809951523314\n",
      "Epoch 790/1000, Loss: 0.06334862671825944\n",
      "Epoch 800/1000, Loss: 0.06334762592272815\n",
      "Epoch 810/1000, Loss: 0.06334739578254561\n",
      "Epoch 820/1000, Loss: 0.06334733480050131\n",
      "Epoch 830/1000, Loss: 0.0633472159201554\n",
      "Epoch 840/1000, Loss: 0.06334718499986246\n",
      "Epoch 850/1000, Loss: 0.06334881398321487\n",
      "Epoch 860/1000, Loss: 0.06349612546076175\n",
      "Epoch 870/1000, Loss: 0.06343511658833269\n",
      "Epoch 880/1000, Loss: 0.06334795282614895\n",
      "Epoch 890/1000, Loss: 0.06335645767328575\n",
      "Epoch 900/1000, Loss: 0.06334757356384325\n",
      "Epoch 910/1000, Loss: 0.06334840129694655\n",
      "Epoch 920/1000, Loss: 0.06334744898699868\n",
      "Epoch 930/1000, Loss: 0.06334678210988426\n",
      "Epoch 940/1000, Loss: 0.06334681222293578\n",
      "Epoch 950/1000, Loss: 0.06334730265549242\n",
      "Epoch 960/1000, Loss: 0.06337615001774424\n",
      "Epoch 970/1000, Loss: 0.0633660355762627\n",
      "Epoch 980/1000, Loss: 0.06335842875281755\n",
      "Epoch 990/1000, Loss: 0.06335707729566815\n",
      "Epoch 1000/1000, Loss: 0.06334709666105545\n",
      "Maximum absolute weight: 1.0183015404410392\n",
      "\n",
      "---------- finished run ----------\n",
      "3\n",
      "Epoch 10/1000, Loss: 0.12786328927339102\n",
      "Epoch 20/1000, Loss: 0.13139642822176423\n",
      "Epoch 30/1000, Loss: 0.11961338474914655\n",
      "Epoch 40/1000, Loss: 0.11386166240433439\n",
      "Epoch 50/1000, Loss: 0.1023312860052241\n",
      "Epoch 60/1000, Loss: 0.0765049615666942\n",
      "Epoch 70/1000, Loss: 0.06610934589891876\n",
      "Epoch 80/1000, Loss: 0.0657154937161153\n",
      "Epoch 90/1000, Loss: 0.0012358683189490698\n",
      "Epoch 100/1000, Loss: 0.0007251357865716676\n",
      "Epoch 110/1000, Loss: 0.0004800251591464916\n",
      "Epoch 120/1000, Loss: 0.00014874334234682662\n",
      "Epoch 130/1000, Loss: 0.00013799228687382293\n",
      "Epoch 140/1000, Loss: 9.2307392353245e-05\n",
      "Epoch 150/1000, Loss: 8.479520614305008e-05\n",
      "Epoch 160/1000, Loss: 6.908999870908097e-05\n",
      "Epoch 170/1000, Loss: 0.00032422131402671584\n",
      "Epoch 180/1000, Loss: 0.0001629504140371947\n",
      "Epoch 190/1000, Loss: 8.949294534066263e-05\n",
      "Epoch 200/1000, Loss: 7.019685936312514e-05\n",
      "Epoch 210/1000, Loss: 4.8036609372645604e-05\n",
      "Epoch 220/1000, Loss: 4.618013945968289e-05\n",
      "Epoch 230/1000, Loss: 5.542476503614044e-05\n",
      "Epoch 240/1000, Loss: 0.0002845897899126102\n",
      "Epoch 250/1000, Loss: 6.484415656942959e-05\n",
      "Epoch 260/1000, Loss: 4.4701489330024814e-05\n",
      "Epoch 270/1000, Loss: 4.202107920353314e-05\n",
      "Epoch 280/1000, Loss: 4.10550694687581e-05\n",
      "Epoch 290/1000, Loss: 5.0786054086251575e-05\n",
      "Epoch 300/1000, Loss: 0.00016148410330470628\n",
      "Epoch 310/1000, Loss: 9.530945303562859e-05\n",
      "Epoch 320/1000, Loss: 3.3034654748525175e-05\n",
      "Epoch 330/1000, Loss: 4.1459853015500483e-05\n",
      "Epoch 340/1000, Loss: 3.5692812598508565e-05\n",
      "Epoch 350/1000, Loss: 2.982701352734756e-05\n",
      "Epoch 360/1000, Loss: 4.975444668534807e-05\n",
      "Epoch 370/1000, Loss: 0.0001951689674132928\n",
      "Epoch 380/1000, Loss: 6.507422982298013e-05\n",
      "Epoch 390/1000, Loss: 3.4792439755610746e-05\n",
      "Epoch 400/1000, Loss: 3.4284513351408365e-05\n",
      "Epoch 410/1000, Loss: 2.591895967805321e-05\n",
      "Epoch 420/1000, Loss: 9.798624598524927e-05\n",
      "Epoch 430/1000, Loss: 2.402435802005321e-05\n",
      "Epoch 440/1000, Loss: 2.3342471617073256e-05\n",
      "Epoch 450/1000, Loss: 2.225683002681097e-05\n",
      "Epoch 460/1000, Loss: 2.1372141343681725e-05\n",
      "Epoch 470/1000, Loss: 2.9036403661905484e-05\n",
      "Epoch 480/1000, Loss: 0.00013220991562037303\n",
      "Epoch 490/1000, Loss: 2.3760215398365288e-05\n",
      "Epoch 500/1000, Loss: 2.1957157969870078e-05\n",
      "Epoch 510/1000, Loss: 1.8905247912554498e-05\n",
      "Epoch 520/1000, Loss: 2.8114306896950092e-05\n",
      "Epoch 530/1000, Loss: 2.075085705781768e-05\n",
      "Epoch 540/1000, Loss: 6.510846361806527e-05\n",
      "Epoch 550/1000, Loss: 4.0424141075335175e-05\n",
      "Epoch 560/1000, Loss: 5.97417548599879e-05\n",
      "Epoch 570/1000, Loss: 3.06252151801054e-05\n",
      "Epoch 580/1000, Loss: 1.713571021210212e-05\n",
      "Epoch 590/1000, Loss: 1.7502330833369824e-05\n",
      "Epoch 600/1000, Loss: 1.5587607509843614e-05\n",
      "Epoch 610/1000, Loss: 1.7400308066082663e-05\n",
      "Epoch 620/1000, Loss: 3.2484415191897975e-05\n",
      "Epoch 630/1000, Loss: 0.00023727583514318465\n",
      "Epoch 640/1000, Loss: 6.426046022185678e-05\n",
      "Epoch 650/1000, Loss: 1.535869351399755e-05\n",
      "Epoch 660/1000, Loss: 1.5234598225917244e-05\n",
      "Epoch 670/1000, Loss: 1.4049553623660701e-05\n",
      "Epoch 680/1000, Loss: 1.841798265979828e-05\n",
      "Epoch 690/1000, Loss: 2.9138144470105242e-05\n",
      "Epoch 700/1000, Loss: 0.00014222621787469232\n",
      "Epoch 710/1000, Loss: 3.114294148638866e-05\n",
      "Epoch 720/1000, Loss: 1.6287700137356885e-05\n",
      "Epoch 730/1000, Loss: 1.6217026151490855e-05\n",
      "Epoch 740/1000, Loss: 1.6993165477549538e-05\n",
      "Epoch 750/1000, Loss: 8.534762471648343e-05\n",
      "Epoch 760/1000, Loss: 2.5098473891703896e-05\n",
      "Epoch 770/1000, Loss: 1.552794645060008e-05\n",
      "Epoch 780/1000, Loss: 1.629004425583699e-05\n",
      "Epoch 790/1000, Loss: 2.000198729400805e-05\n",
      "Epoch 800/1000, Loss: 1.1782022875957864e-05\n",
      "Epoch 810/1000, Loss: 1.1040193999947115e-05\n",
      "Epoch 820/1000, Loss: 1.4705603764399388e-05\n",
      "Epoch 830/1000, Loss: 0.0005411818357785617\n",
      "Epoch 840/1000, Loss: 3.8184856134553515e-05\n",
      "Epoch 850/1000, Loss: 4.059191021246858e-05\n",
      "Epoch 860/1000, Loss: 3.0333726934526685e-05\n",
      "Epoch 870/1000, Loss: 1.5391938067354774e-05\n",
      "Epoch 880/1000, Loss: 1.0558877909254987e-05\n",
      "Epoch 890/1000, Loss: 1.080844455662402e-05\n",
      "Epoch 900/1000, Loss: 1.0143381715097559e-05\n",
      "Epoch 910/1000, Loss: 9.627299077512895e-06\n",
      "Epoch 920/1000, Loss: 9.397310240520157e-06\n",
      "Epoch 930/1000, Loss: 9.138137295861078e-06\n",
      "Epoch 940/1000, Loss: 9.168975750802816e-06\n",
      "Epoch 950/1000, Loss: 1.602914105067056e-05\n",
      "Epoch 960/1000, Loss: 0.0002558918487577608\n",
      "Epoch 970/1000, Loss: 0.00010047272763384042\n",
      "Epoch 980/1000, Loss: 2.6515356967161745e-05\n",
      "Epoch 990/1000, Loss: 8.724810487240838e-06\n",
      "Epoch 1000/1000, Loss: 9.237046722002267e-06\n",
      "Maximum absolute weight: 0.5507033467380212\n",
      "\n",
      "---------- finished run ----------\n",
      "4\n",
      "Epoch 10/1000, Loss: 0.136902490453491\n",
      "Epoch 20/1000, Loss: 0.12727816848673354\n",
      "Epoch 30/1000, Loss: 0.11774584842456624\n",
      "Epoch 40/1000, Loss: 0.11037853549833705\n",
      "Epoch 50/1000, Loss: 0.09362449756785275\n",
      "Epoch 60/1000, Loss: 0.07170255396123974\n",
      "Epoch 70/1000, Loss: 0.06453341255996146\n",
      "Epoch 80/1000, Loss: 0.0012994469545733638\n",
      "Epoch 90/1000, Loss: 0.0006185987401677768\n",
      "Epoch 100/1000, Loss: 0.0003298552534967248\n",
      "Epoch 110/1000, Loss: 0.00026613534114131076\n",
      "Epoch 120/1000, Loss: 0.00023837124853772542\n",
      "Epoch 130/1000, Loss: 0.00016751351304576537\n",
      "Epoch 140/1000, Loss: 9.354057506622686e-05\n",
      "Epoch 150/1000, Loss: 7.046365951210178e-05\n",
      "Epoch 160/1000, Loss: 5.373795618567548e-05\n",
      "Epoch 170/1000, Loss: 9.662481167656255e-05\n",
      "Epoch 180/1000, Loss: 5.5109984420754586e-05\n",
      "Epoch 190/1000, Loss: 0.00018069235106047985\n",
      "Epoch 200/1000, Loss: 0.00010828798665091149\n",
      "Epoch 210/1000, Loss: 4.245901246971496e-05\n",
      "Epoch 220/1000, Loss: 4.097517951056167e-05\n",
      "Epoch 230/1000, Loss: 3.352093460908565e-05\n",
      "Epoch 240/1000, Loss: 8.911402613619449e-05\n",
      "Epoch 250/1000, Loss: 4.008022862658017e-05\n",
      "Epoch 260/1000, Loss: 4.510553060952454e-05\n",
      "Epoch 270/1000, Loss: 5.7857994542037014e-05\n",
      "Epoch 280/1000, Loss: 3.197645048986052e-05\n",
      "Epoch 290/1000, Loss: 0.00017090199290537673\n",
      "Epoch 300/1000, Loss: 0.00014146920602812677\n",
      "Epoch 310/1000, Loss: 3.8993311966123084e-05\n",
      "Epoch 320/1000, Loss: 3.350415719638627e-05\n",
      "Epoch 330/1000, Loss: 3.035354182674396e-05\n",
      "Epoch 340/1000, Loss: 2.387850142166097e-05\n",
      "Epoch 350/1000, Loss: 3.0325180594775962e-05\n",
      "Epoch 360/1000, Loss: 0.00023500092974206908\n",
      "Epoch 370/1000, Loss: 0.00011252612589119445\n",
      "Epoch 380/1000, Loss: 4.2378002729267556e-05\n",
      "Epoch 390/1000, Loss: 2.213388069515407e-05\n",
      "Epoch 400/1000, Loss: 2.2977116207103046e-05\n",
      "Epoch 410/1000, Loss: 1.5183266779389682e-05\n",
      "Epoch 420/1000, Loss: 3.5017529756114397e-05\n",
      "Epoch 430/1000, Loss: 0.00017736293954039698\n",
      "Epoch 440/1000, Loss: 0.00010542834004542223\n",
      "Epoch 450/1000, Loss: 1.9008192450879863e-05\n",
      "Epoch 460/1000, Loss: 1.76742675585794e-05\n",
      "Epoch 470/1000, Loss: 1.8057649489828666e-05\n",
      "Epoch 480/1000, Loss: 1.4348299813826759e-05\n",
      "Epoch 490/1000, Loss: 1.3188166744190775e-05\n",
      "Epoch 500/1000, Loss: 1.2554877263237556e-05\n",
      "Epoch 510/1000, Loss: 1.314803044121975e-05\n",
      "Epoch 520/1000, Loss: 0.00011652197683085557\n",
      "Epoch 530/1000, Loss: 7.645941300362004e-05\n",
      "Epoch 540/1000, Loss: 5.802988687050667e-05\n",
      "Epoch 550/1000, Loss: 2.8239231623943057e-05\n",
      "Epoch 560/1000, Loss: 1.3295027198382185e-05\n",
      "Epoch 570/1000, Loss: 1.2117124213637615e-05\n",
      "Epoch 580/1000, Loss: 1.1680918972239073e-05\n",
      "Epoch 590/1000, Loss: 1.0286188630956413e-05\n",
      "Epoch 600/1000, Loss: 1.162359191637906e-05\n",
      "Epoch 610/1000, Loss: 2.8026115896298352e-05\n",
      "Epoch 620/1000, Loss: 0.00019989582092931404\n",
      "Epoch 630/1000, Loss: 8.454213442015e-05\n",
      "Epoch 640/1000, Loss: 3.284819847115058e-05\n",
      "Epoch 650/1000, Loss: 1.8513639459814012e-05\n",
      "Epoch 660/1000, Loss: 1.3125701423075962e-05\n",
      "Epoch 670/1000, Loss: 9.521086591191463e-06\n",
      "Epoch 680/1000, Loss: 8.537923475828979e-06\n",
      "Epoch 690/1000, Loss: 1.6524455130426287e-05\n",
      "Epoch 700/1000, Loss: 0.00046836710657784596\n",
      "Epoch 710/1000, Loss: 6.271321244707096e-05\n",
      "Epoch 720/1000, Loss: 9.098511690106283e-06\n",
      "Epoch 730/1000, Loss: 1.380939468983122e-05\n",
      "Epoch 740/1000, Loss: 1.438171154371176e-05\n",
      "Epoch 750/1000, Loss: 8.508345084749081e-06\n",
      "Epoch 760/1000, Loss: 8.719117379363081e-06\n",
      "Epoch 770/1000, Loss: 7.763621152493871e-06\n",
      "Epoch 780/1000, Loss: 7.440758288811838e-06\n",
      "Epoch 790/1000, Loss: 7.1761770987561714e-06\n",
      "Epoch 800/1000, Loss: 6.994792383358741e-06\n",
      "Epoch 810/1000, Loss: 6.881167928971272e-06\n",
      "Epoch 820/1000, Loss: 9.193853062270921e-06\n",
      "Epoch 830/1000, Loss: 0.00035584683901168055\n",
      "Epoch 840/1000, Loss: 0.00015307268457187648\n",
      "Epoch 850/1000, Loss: 1.900527444945484e-05\n",
      "Epoch 860/1000, Loss: 1.5053575303196647e-05\n",
      "Epoch 870/1000, Loss: 1.282168886580518e-05\n",
      "Epoch 880/1000, Loss: 7.829992043490018e-06\n",
      "Epoch 890/1000, Loss: 6.346434959153674e-06\n",
      "Epoch 900/1000, Loss: 6.174816196465564e-06\n",
      "Epoch 910/1000, Loss: 6.224427910646843e-06\n",
      "Epoch 920/1000, Loss: 5.918042173206679e-06\n",
      "Epoch 930/1000, Loss: 6.054279911939125e-06\n",
      "Epoch 940/1000, Loss: 1.8247143274695737e-05\n",
      "Epoch 950/1000, Loss: 0.0002754522416014253\n",
      "Epoch 960/1000, Loss: 4.2208876218989326e-05\n",
      "Epoch 970/1000, Loss: 8.853328191618646e-06\n",
      "Epoch 980/1000, Loss: 1.567808117739023e-05\n",
      "Epoch 990/1000, Loss: 9.827970351533363e-06\n",
      "Epoch 1000/1000, Loss: 7.2737002952694414e-06\n",
      "Maximum absolute weight: 0.7179030929598236\n",
      "\n",
      "---------- finished run ----------\n",
      "5\n",
      "Epoch 10/1000, Loss: 0.11291784904587328\n",
      "Epoch 20/1000, Loss: 0.12137695846132544\n",
      "Epoch 30/1000, Loss: 0.06120305789142826\n",
      "Epoch 40/1000, Loss: 0.05088243851353585\n",
      "Epoch 50/1000, Loss: 0.04447578727157808\n",
      "Epoch 60/1000, Loss: 0.030619729040634598\n",
      "Epoch 70/1000, Loss: 0.010638237467481566\n",
      "Epoch 80/1000, Loss: 0.0007575858314582088\n",
      "Epoch 90/1000, Loss: 0.001442872414276227\n",
      "Epoch 100/1000, Loss: 0.0004977905437454281\n",
      "Epoch 110/1000, Loss: 0.0003317825513294997\n",
      "Epoch 120/1000, Loss: 0.00015140415609633443\n",
      "Epoch 130/1000, Loss: 0.00011280814266905831\n",
      "Epoch 140/1000, Loss: 9.883825427450353e-05\n",
      "Epoch 150/1000, Loss: 8.812467990023623e-05\n",
      "Epoch 160/1000, Loss: 8.028052659311167e-05\n",
      "Epoch 170/1000, Loss: 7.498759335204746e-05\n",
      "Epoch 180/1000, Loss: 7.046019877610449e-05\n",
      "Epoch 190/1000, Loss: 6.673356744296816e-05\n",
      "Epoch 200/1000, Loss: 6.346388788831079e-05\n",
      "Epoch 210/1000, Loss: 6.0508655261343534e-05\n",
      "Epoch 220/1000, Loss: 5.793729040712058e-05\n",
      "Epoch 230/1000, Loss: 5.568698011948666e-05\n",
      "Epoch 240/1000, Loss: 5.3670494814402044e-05\n",
      "Epoch 250/1000, Loss: 5.180724479430795e-05\n",
      "Epoch 260/1000, Loss: 5.002851557591117e-05\n",
      "Epoch 270/1000, Loss: 4.8298347815595584e-05\n",
      "Epoch 280/1000, Loss: 4.668618871157712e-05\n",
      "Epoch 290/1000, Loss: 0.0005789180391946255\n",
      "Epoch 300/1000, Loss: 0.0002229785849885923\n",
      "Epoch 310/1000, Loss: 0.00013572479325607852\n",
      "Epoch 320/1000, Loss: 7.698800070604678e-05\n",
      "Epoch 330/1000, Loss: 5.1830969670185655e-05\n",
      "Epoch 340/1000, Loss: 4.148461279551188e-05\n",
      "Epoch 350/1000, Loss: 3.976583114085338e-05\n",
      "Epoch 360/1000, Loss: 3.8627012367529386e-05\n",
      "Epoch 370/1000, Loss: 3.723582800466864e-05\n",
      "Epoch 380/1000, Loss: 3.6056146710031807e-05\n",
      "Epoch 390/1000, Loss: 3.504898936530335e-05\n",
      "Epoch 400/1000, Loss: 3.410059083649125e-05\n",
      "Epoch 410/1000, Loss: 3.3172593629241934e-05\n",
      "Epoch 420/1000, Loss: 3.2261076577209514e-05\n",
      "Epoch 430/1000, Loss: 3.137875454732289e-05\n",
      "Epoch 440/1000, Loss: 3.0541368489057475e-05\n",
      "Epoch 450/1000, Loss: 2.973343883613141e-05\n",
      "Epoch 460/1000, Loss: 2.9234891897695437e-05\n",
      "Epoch 470/1000, Loss: 0.00016130926965018125\n",
      "Epoch 480/1000, Loss: 0.00019880221199058336\n",
      "Epoch 490/1000, Loss: 7.286135500076765e-05\n",
      "Epoch 500/1000, Loss: 3.2171031385017104e-05\n",
      "Epoch 510/1000, Loss: 2.6467830545356938e-05\n",
      "Epoch 520/1000, Loss: 2.571617137866682e-05\n",
      "Epoch 530/1000, Loss: 2.546412260200186e-05\n",
      "Epoch 540/1000, Loss: 2.4785248292995604e-05\n",
      "Epoch 550/1000, Loss: 2.366094952748465e-05\n",
      "Epoch 560/1000, Loss: 2.3127879832554225e-05\n",
      "Epoch 570/1000, Loss: 2.259774639130304e-05\n",
      "Epoch 580/1000, Loss: 2.207037958567166e-05\n",
      "Epoch 590/1000, Loss: 2.157471480153482e-05\n",
      "Epoch 600/1000, Loss: 2.1133921154590298e-05\n",
      "Epoch 610/1000, Loss: 2.1469490722142138e-05\n",
      "Epoch 620/1000, Loss: 0.00027766596517970517\n",
      "Epoch 630/1000, Loss: 7.43629566693567e-05\n",
      "Epoch 640/1000, Loss: 4.594536464521913e-05\n",
      "Epoch 650/1000, Loss: 2.707333159127724e-05\n",
      "Epoch 660/1000, Loss: 2.1740484548099546e-05\n",
      "Epoch 670/1000, Loss: 2.0892984343655342e-05\n",
      "Epoch 680/1000, Loss: 1.9481846660508503e-05\n",
      "Epoch 690/1000, Loss: 1.7826031451683477e-05\n",
      "Epoch 700/1000, Loss: 1.7611003849285953e-05\n",
      "Epoch 710/1000, Loss: 1.7180922613541536e-05\n",
      "Epoch 720/1000, Loss: 1.67464895435477e-05\n",
      "Epoch 730/1000, Loss: 1.6455053411716264e-05\n",
      "Epoch 740/1000, Loss: 1.6140459110396396e-05\n",
      "Epoch 750/1000, Loss: 1.6940975093717078e-05\n",
      "Epoch 760/1000, Loss: 7.210390104557987e-05\n",
      "Epoch 770/1000, Loss: 1.6829321694787997e-05\n",
      "Epoch 780/1000, Loss: 4.550152281284776e-05\n",
      "Epoch 790/1000, Loss: 2.3201919650152462e-05\n",
      "Epoch 800/1000, Loss: 1.4916944373207505e-05\n",
      "Epoch 810/1000, Loss: 1.442003787583981e-05\n",
      "Epoch 820/1000, Loss: 1.4801446644203469e-05\n",
      "Epoch 830/1000, Loss: 1.4150978229155786e-05\n",
      "Epoch 840/1000, Loss: 1.67253595090507e-05\n",
      "Epoch 850/1000, Loss: 7.290457034441162e-05\n",
      "Epoch 860/1000, Loss: 1.4259804258873816e-05\n",
      "Epoch 870/1000, Loss: 2.6322596352867492e-05\n",
      "Epoch 880/1000, Loss: 2.4627488420373187e-05\n",
      "Epoch 890/1000, Loss: 1.735465534951292e-05\n",
      "Epoch 900/1000, Loss: 1.4839188008482887e-05\n",
      "Epoch 910/1000, Loss: 1.2506791188588707e-05\n",
      "Epoch 920/1000, Loss: 1.4931385530451728e-05\n",
      "Epoch 930/1000, Loss: 4.1298290311993876e-05\n",
      "Epoch 940/1000, Loss: 9.600483256794479e-05\n",
      "Epoch 950/1000, Loss: 2.7246629594406547e-05\n",
      "Epoch 960/1000, Loss: 1.218659335613826e-05\n",
      "Epoch 970/1000, Loss: 1.134166614556754e-05\n",
      "Epoch 980/1000, Loss: 1.156786114579775e-05\n",
      "Epoch 990/1000, Loss: 1.234446225642597e-05\n",
      "Epoch 1000/1000, Loss: 1.6734520161053786e-05\n",
      "Maximum absolute weight: 0.6004819654985081\n",
      "\n",
      "---------- finished run ----------\n",
      "6\n",
      "Epoch 10/1000, Loss: 0.15567515161428414\n",
      "Epoch 20/1000, Loss: 0.13095674988183761\n",
      "Epoch 30/1000, Loss: 0.12325131861457007\n",
      "Epoch 40/1000, Loss: 0.11275230294591844\n",
      "Epoch 50/1000, Loss: 0.09907002254256764\n",
      "Epoch 60/1000, Loss: 0.07665624140142845\n",
      "Epoch 70/1000, Loss: 0.06521582578906115\n",
      "Epoch 80/1000, Loss: 0.001873489940939662\n",
      "Epoch 90/1000, Loss: 0.0008378963459293064\n",
      "Epoch 100/1000, Loss: 0.06401106600251774\n",
      "Epoch 110/1000, Loss: 0.06365670650934555\n",
      "Epoch 120/1000, Loss: 0.06349098556786456\n",
      "Epoch 130/1000, Loss: 0.06345553501571426\n",
      "Epoch 140/1000, Loss: 0.06344054614621224\n",
      "Epoch 150/1000, Loss: 0.06342181294107196\n",
      "Epoch 160/1000, Loss: 0.06341349297155285\n",
      "Epoch 170/1000, Loss: 0.06340573854657873\n",
      "Epoch 180/1000, Loss: 0.0634054204964168\n",
      "Epoch 190/1000, Loss: 0.06347305710110518\n",
      "Epoch 200/1000, Loss: 0.06339543571951865\n",
      "Epoch 210/1000, Loss: 0.06339892104956475\n",
      "Epoch 220/1000, Loss: 0.06339428683420022\n",
      "Epoch 230/1000, Loss: 0.06338671658773443\n",
      "Epoch 240/1000, Loss: 0.06338621754049927\n",
      "Epoch 250/1000, Loss: 0.06338336087475857\n",
      "Epoch 260/1000, Loss: 0.06338088777958635\n",
      "Epoch 270/1000, Loss: 0.06353554014211206\n",
      "Epoch 280/1000, Loss: 0.06339661895329911\n",
      "Epoch 290/1000, Loss: 0.06337716216405354\n",
      "Epoch 300/1000, Loss: 0.0633748125735009\n",
      "Epoch 310/1000, Loss: 0.06337396889232545\n",
      "Epoch 320/1000, Loss: 0.06337466098719759\n",
      "Epoch 330/1000, Loss: 0.06337101085685859\n",
      "Epoch 340/1000, Loss: 0.06337097474940835\n",
      "Epoch 350/1000, Loss: 0.06337593047883276\n",
      "Epoch 360/1000, Loss: 0.06342458161484614\n",
      "Epoch 370/1000, Loss: 0.06337488378714089\n",
      "Epoch 380/1000, Loss: 0.0633840246618698\n",
      "Epoch 390/1000, Loss: 0.06337024533091892\n",
      "Epoch 400/1000, Loss: 0.06344714550958454\n",
      "Epoch 410/1000, Loss: 0.06338745943407977\n",
      "Epoch 420/1000, Loss: 0.06336708691262664\n",
      "Epoch 430/1000, Loss: 0.06336220567975899\n",
      "Epoch 440/1000, Loss: 0.06337138534906629\n",
      "Epoch 450/1000, Loss: 0.06345962344111479\n",
      "Epoch 460/1000, Loss: 0.06339603889938537\n",
      "Epoch 470/1000, Loss: 0.06337380515485964\n",
      "Epoch 480/1000, Loss: 0.06336289363156161\n",
      "Epoch 490/1000, Loss: 0.06336581027303327\n",
      "Epoch 500/1000, Loss: 0.06338403637878286\n",
      "Epoch 510/1000, Loss: 0.06340143481759351\n",
      "Epoch 520/1000, Loss: 0.06337658854458066\n",
      "Epoch 530/1000, Loss: 0.06336739223717723\n",
      "Epoch 540/1000, Loss: 0.06336068190319599\n",
      "Epoch 550/1000, Loss: 0.06336266095116713\n",
      "Epoch 560/1000, Loss: 0.0633932644701172\n",
      "Epoch 570/1000, Loss: 0.06337917550642676\n",
      "Epoch 580/1000, Loss: 0.06335987967255334\n",
      "Epoch 590/1000, Loss: 0.06335597582849957\n",
      "Epoch 600/1000, Loss: 0.06335660502266434\n",
      "Epoch 610/1000, Loss: 0.06335748078829526\n",
      "Epoch 620/1000, Loss: 0.06336456723254771\n",
      "Epoch 630/1000, Loss: 0.06346389518768754\n",
      "Epoch 640/1000, Loss: 0.06338984195297295\n",
      "Epoch 650/1000, Loss: 0.0633703055143769\n",
      "Epoch 660/1000, Loss: 0.06336033721394031\n",
      "Epoch 670/1000, Loss: 0.0633561827575545\n",
      "Epoch 680/1000, Loss: 0.0633531708561583\n",
      "Epoch 690/1000, Loss: 0.06335347560010776\n",
      "Epoch 700/1000, Loss: 0.06339972834155741\n",
      "Epoch 710/1000, Loss: 0.06335473346653415\n",
      "Epoch 720/1000, Loss: 0.06339372196511875\n",
      "Epoch 730/1000, Loss: 0.063353378475091\n",
      "Epoch 740/1000, Loss: 0.06335743788267967\n",
      "Epoch 750/1000, Loss: 0.0633518485337734\n",
      "Epoch 760/1000, Loss: 0.06335147213594018\n",
      "Epoch 770/1000, Loss: 0.0633511734354971\n",
      "Epoch 780/1000, Loss: 0.06335099752452045\n",
      "Epoch 790/1000, Loss: 0.06335079902013614\n",
      "Epoch 800/1000, Loss: 0.06335217950197093\n",
      "Epoch 810/1000, Loss: 0.06345810992945755\n",
      "Epoch 820/1000, Loss: 0.06342805318277844\n",
      "Epoch 830/1000, Loss: 0.06335288822507416\n",
      "Epoch 840/1000, Loss: 0.06336176010979344\n",
      "Epoch 850/1000, Loss: 0.06335164783430747\n",
      "Epoch 860/1000, Loss: 0.06335104966784216\n",
      "Epoch 870/1000, Loss: 0.06334947401553605\n",
      "Epoch 880/1000, Loss: 0.06334929517719687\n",
      "Epoch 890/1000, Loss: 0.06334908486026074\n",
      "Epoch 900/1000, Loss: 0.06334903037378001\n",
      "Epoch 910/1000, Loss: 0.0633491173216783\n",
      "Epoch 920/1000, Loss: 0.06335850907528569\n",
      "Epoch 930/1000, Loss: 0.06355074011001181\n",
      "Epoch 940/1000, Loss: 0.06335575586021959\n",
      "Epoch 950/1000, Loss: 0.06336776193863833\n",
      "Epoch 960/1000, Loss: 0.06334847434087831\n",
      "Epoch 970/1000, Loss: 0.06335096185510185\n",
      "Epoch 980/1000, Loss: 0.06334823904133292\n",
      "Epoch 990/1000, Loss: 0.06334782450324859\n",
      "Epoch 1000/1000, Loss: 0.06334766971847995\n",
      "Maximum absolute weight: 0.9038138537737208\n",
      "\n",
      "---------- finished run ----------\n",
      "7\n",
      "Epoch 10/1000, Loss: 0.1243945473958126\n",
      "Epoch 20/1000, Loss: 0.12040346452275989\n",
      "Epoch 30/1000, Loss: 0.11292831062030385\n",
      "Epoch 40/1000, Loss: 0.10659950240916412\n",
      "Epoch 50/1000, Loss: 0.09096159108557073\n",
      "Epoch 60/1000, Loss: 0.0072738812977629535\n",
      "Epoch 70/1000, Loss: 0.0026734152329997893\n",
      "Epoch 80/1000, Loss: 0.0017062701194163722\n",
      "Epoch 90/1000, Loss: 0.0006801241390708214\n",
      "Epoch 100/1000, Loss: 0.0002534499333005547\n",
      "Epoch 110/1000, Loss: 0.0001578395413724679\n",
      "Epoch 120/1000, Loss: 0.00012477412281859776\n",
      "Epoch 130/1000, Loss: 0.00019437298667321083\n",
      "Epoch 140/1000, Loss: 7.927785767391566e-05\n",
      "Epoch 150/1000, Loss: 8.617273707630293e-05\n",
      "Epoch 160/1000, Loss: 7.32589405801941e-05\n",
      "Epoch 170/1000, Loss: 6.585677726195085e-05\n",
      "Epoch 180/1000, Loss: 0.00016885354239913207\n",
      "Epoch 190/1000, Loss: 5.260509902557844e-05\n",
      "Epoch 200/1000, Loss: 6.430834584567037e-05\n",
      "Epoch 210/1000, Loss: 4.85098485338487e-05\n",
      "Epoch 220/1000, Loss: 5.2133048381657496e-05\n",
      "Epoch 230/1000, Loss: 9.66335600872533e-05\n",
      "Epoch 240/1000, Loss: 4.258735511835585e-05\n",
      "Epoch 250/1000, Loss: 4.320999901060993e-05\n",
      "Epoch 260/1000, Loss: 5.465408169242168e-05\n",
      "Epoch 270/1000, Loss: 7.353438094068902e-05\n",
      "Epoch 280/1000, Loss: 6.13055615505183e-05\n",
      "Epoch 290/1000, Loss: 3.934237774525394e-05\n",
      "Epoch 300/1000, Loss: 5.5152652798442794e-05\n",
      "Epoch 310/1000, Loss: 3.999624722187665e-05\n",
      "Epoch 320/1000, Loss: 4.0347684624950723e-05\n",
      "Epoch 330/1000, Loss: 0.00016129616352003227\n",
      "Epoch 340/1000, Loss: 3.594671634913956e-05\n",
      "Epoch 350/1000, Loss: 2.9860245986120577e-05\n",
      "Epoch 360/1000, Loss: 3.066342485715228e-05\n",
      "Epoch 370/1000, Loss: 2.5385555072023875e-05\n",
      "Epoch 380/1000, Loss: 2.747869140371068e-05\n",
      "Epoch 390/1000, Loss: 5.345744943779575e-05\n",
      "Epoch 400/1000, Loss: 4.508761968518131e-05\n",
      "Epoch 410/1000, Loss: 2.080570172781675e-05\n",
      "Epoch 420/1000, Loss: 2.5335793242992146e-05\n",
      "Epoch 430/1000, Loss: 2.1394351257538666e-05\n",
      "Epoch 440/1000, Loss: 2.0131851158665648e-05\n",
      "Epoch 450/1000, Loss: 1.857022210786335e-05\n",
      "Epoch 460/1000, Loss: 3.355575664378649e-05\n",
      "Epoch 470/1000, Loss: 6.884225262459369e-05\n",
      "Epoch 480/1000, Loss: 6.228503317476834e-05\n",
      "Epoch 490/1000, Loss: 2.5214273925876054e-05\n",
      "Epoch 500/1000, Loss: 1.806718643688048e-05\n",
      "Epoch 510/1000, Loss: 1.6879812054045052e-05\n",
      "Epoch 520/1000, Loss: 1.6697841657899008e-05\n",
      "Epoch 530/1000, Loss: 1.6074104504749004e-05\n",
      "Epoch 540/1000, Loss: 1.5219109634519953e-05\n",
      "Epoch 550/1000, Loss: 1.481887527670448e-05\n",
      "Epoch 560/1000, Loss: 1.44810598261624e-05\n",
      "Epoch 570/1000, Loss: 1.420585549300088e-05\n",
      "Epoch 580/1000, Loss: 1.3896691281543722e-05\n",
      "Epoch 590/1000, Loss: 1.393307091797448e-05\n",
      "Epoch 600/1000, Loss: 6.654358566788472e-05\n",
      "Epoch 610/1000, Loss: 0.00011852089825291536\n",
      "Epoch 620/1000, Loss: 4.3003435179008465e-05\n",
      "Epoch 630/1000, Loss: 3.560667210519607e-05\n",
      "Epoch 640/1000, Loss: 2.0862687711101517e-05\n",
      "Epoch 650/1000, Loss: 1.5119499168957244e-05\n",
      "Epoch 660/1000, Loss: 1.3271289758190363e-05\n",
      "Epoch 670/1000, Loss: 1.2358081813132272e-05\n",
      "Epoch 680/1000, Loss: 1.1658366766600659e-05\n",
      "Epoch 690/1000, Loss: 1.1466727167181507e-05\n",
      "Epoch 700/1000, Loss: 1.1179282816522203e-05\n",
      "Epoch 710/1000, Loss: 1.0961615092941306e-05\n",
      "Epoch 720/1000, Loss: 1.074898759832748e-05\n",
      "Epoch 730/1000, Loss: 1.05444167506123e-05\n",
      "Epoch 740/1000, Loss: 1.0352929084072728e-05\n",
      "Epoch 750/1000, Loss: 1.0173531741520547e-05\n",
      "Epoch 760/1000, Loss: 1.0583043573408865e-05\n",
      "Epoch 770/1000, Loss: 0.00013581246405963278\n",
      "Epoch 780/1000, Loss: 0.0001759195738902205\n",
      "Epoch 790/1000, Loss: 5.022845476080217e-05\n",
      "Epoch 800/1000, Loss: 2.5727514644812043e-05\n",
      "Epoch 810/1000, Loss: 1.5445664130445847e-05\n",
      "Epoch 820/1000, Loss: 1.0958058981826145e-05\n",
      "Epoch 830/1000, Loss: 9.262762428402507e-06\n",
      "Epoch 840/1000, Loss: 9.039435852799327e-06\n",
      "Epoch 850/1000, Loss: 8.87836358705353e-06\n",
      "Epoch 860/1000, Loss: 8.649012966361623e-06\n",
      "Epoch 870/1000, Loss: 8.48547540666239e-06\n",
      "Epoch 880/1000, Loss: 8.35555337818868e-06\n",
      "Epoch 890/1000, Loss: 8.227572969397333e-06\n",
      "Epoch 900/1000, Loss: 8.108325439447015e-06\n",
      "Epoch 910/1000, Loss: 7.989944836705517e-06\n",
      "Epoch 920/1000, Loss: 7.970828902329789e-06\n",
      "Epoch 930/1000, Loss: 1.17397557908187e-05\n",
      "Epoch 940/1000, Loss: 0.00023687829380042552\n",
      "Epoch 950/1000, Loss: 8.281578342175333e-05\n",
      "Epoch 960/1000, Loss: 2.7536563322097196e-05\n",
      "Epoch 970/1000, Loss: 7.635600859935063e-06\n",
      "Epoch 980/1000, Loss: 1.0561238206248378e-05\n",
      "Epoch 990/1000, Loss: 8.027242097434767e-06\n",
      "Epoch 1000/1000, Loss: 7.598992637066527e-06\n",
      "Maximum absolute weight: 0.5643241224379663\n",
      "\n",
      "---------- finished run ----------\n",
      "8\n",
      "Epoch 10/1000, Loss: 0.16552009505768536\n",
      "Epoch 20/1000, Loss: 0.1196096493818869\n",
      "Epoch 30/1000, Loss: 0.12127247618034805\n",
      "Epoch 40/1000, Loss: 0.11434594719975005\n",
      "Epoch 50/1000, Loss: 0.1090102696742182\n",
      "Epoch 60/1000, Loss: 0.10044886834088322\n",
      "Epoch 70/1000, Loss: 0.08309771708350687\n",
      "Epoch 80/1000, Loss: 0.003776017909134691\n",
      "Epoch 90/1000, Loss: 0.0015808987646586752\n",
      "Epoch 100/1000, Loss: 0.0006822674231113367\n",
      "Epoch 110/1000, Loss: 0.0003837853904555754\n",
      "Epoch 120/1000, Loss: 0.0001973555560298392\n",
      "Epoch 130/1000, Loss: 8.797146462937373e-05\n",
      "Epoch 140/1000, Loss: 6.330765789954556e-05\n",
      "Epoch 150/1000, Loss: 0.06338379429637918\n",
      "Epoch 160/1000, Loss: 0.06337548452342522\n",
      "Epoch 170/1000, Loss: 0.0634120803612964\n",
      "Epoch 180/1000, Loss: 0.06337176631911283\n",
      "Epoch 190/1000, Loss: 0.06336268662647024\n",
      "Epoch 200/1000, Loss: 0.06336345242755627\n",
      "Epoch 210/1000, Loss: 0.06335996040509917\n",
      "Epoch 220/1000, Loss: 0.0633583654620862\n",
      "Epoch 230/1000, Loss: 0.06337029651757865\n",
      "Epoch 240/1000, Loss: 0.06343599074116009\n",
      "Epoch 250/1000, Loss: 0.06339637991638275\n",
      "Epoch 260/1000, Loss: 0.06335935505169236\n",
      "Epoch 270/1000, Loss: 0.06335521046176247\n",
      "Epoch 280/1000, Loss: 0.06335505982561718\n",
      "Epoch 290/1000, Loss: 0.06335480665021555\n",
      "Epoch 300/1000, Loss: 0.06335390931260028\n",
      "Epoch 310/1000, Loss: 0.06335332796179782\n",
      "Epoch 320/1000, Loss: 0.06336703711154867\n",
      "Epoch 330/1000, Loss: 0.06336831777649402\n",
      "Epoch 340/1000, Loss: 0.06336559168156229\n",
      "Epoch 350/1000, Loss: 0.06336567289766948\n",
      "Epoch 360/1000, Loss: 0.06335831345596617\n",
      "Epoch 370/1000, Loss: 0.06335352689377365\n",
      "Epoch 380/1000, Loss: 0.06335206321168757\n",
      "Epoch 390/1000, Loss: 0.06335155523098436\n",
      "Epoch 400/1000, Loss: 0.06335133890103829\n",
      "Epoch 410/1000, Loss: 0.06335140696408553\n",
      "Epoch 420/1000, Loss: 0.06337017196908845\n",
      "Epoch 430/1000, Loss: 0.06337667584327193\n",
      "Epoch 440/1000, Loss: 0.06337422629462623\n",
      "Epoch 450/1000, Loss: 0.06336614262492192\n",
      "Epoch 460/1000, Loss: 0.06335407167649319\n",
      "Epoch 470/1000, Loss: 0.06335185559295753\n",
      "Epoch 480/1000, Loss: 0.06335134637959658\n",
      "Epoch 490/1000, Loss: 0.06335034204486832\n",
      "Epoch 500/1000, Loss: 0.06335026715870831\n",
      "Epoch 510/1000, Loss: 0.06335001243939915\n",
      "Epoch 520/1000, Loss: 0.06334975458044337\n",
      "Epoch 530/1000, Loss: 0.06334974221210463\n",
      "Epoch 540/1000, Loss: 0.06336809551833017\n",
      "Epoch 550/1000, Loss: 0.06336158001769475\n",
      "Epoch 560/1000, Loss: 0.06336516606310484\n",
      "Epoch 570/1000, Loss: 0.0633650786145855\n",
      "Epoch 580/1000, Loss: 0.06335326313250926\n",
      "Epoch 590/1000, Loss: 0.06335026705366989\n",
      "Epoch 600/1000, Loss: 0.06334976232105193\n",
      "Epoch 610/1000, Loss: 0.06334924682540685\n",
      "Epoch 620/1000, Loss: 0.06334895453674072\n",
      "Epoch 630/1000, Loss: 0.06334873157039807\n",
      "Epoch 640/1000, Loss: 0.06334858365297652\n",
      "Epoch 650/1000, Loss: 0.06334845853482361\n",
      "Epoch 660/1000, Loss: 0.06334839058261256\n",
      "Epoch 670/1000, Loss: 0.06335051875275166\n",
      "Epoch 680/1000, Loss: 0.0636011751868753\n",
      "Epoch 690/1000, Loss: 0.06337297040372492\n",
      "Epoch 700/1000, Loss: 0.06337013600240032\n",
      "Epoch 710/1000, Loss: 0.06335712336100781\n",
      "Epoch 720/1000, Loss: 0.06335081211704037\n",
      "Epoch 730/1000, Loss: 0.06334914739933831\n",
      "Epoch 740/1000, Loss: 0.06334842419081467\n",
      "Epoch 750/1000, Loss: 0.06334775669943685\n",
      "Epoch 760/1000, Loss: 0.06334771822282126\n",
      "Epoch 770/1000, Loss: 0.06334757624678602\n",
      "Epoch 780/1000, Loss: 0.06334742932053673\n",
      "Epoch 790/1000, Loss: 0.06334733920810869\n",
      "Epoch 800/1000, Loss: 0.06334725020024898\n",
      "Epoch 810/1000, Loss: 0.06334759562880522\n",
      "Epoch 820/1000, Loss: 0.0634001965273859\n",
      "Epoch 830/1000, Loss: 0.06342850749493582\n",
      "Epoch 840/1000, Loss: 0.06337270282945148\n",
      "Epoch 850/1000, Loss: 0.0633595083631084\n",
      "Epoch 860/1000, Loss: 0.06335205028880331\n",
      "Epoch 870/1000, Loss: 0.06334882675309006\n",
      "Epoch 880/1000, Loss: 0.06334716854003153\n",
      "Epoch 890/1000, Loss: 0.06334694792942867\n",
      "Epoch 900/1000, Loss: 0.06334677905958662\n",
      "Epoch 910/1000, Loss: 0.0633467068441201\n",
      "Epoch 920/1000, Loss: 0.06334660892566304\n",
      "Epoch 930/1000, Loss: 0.06334657192488358\n",
      "Epoch 940/1000, Loss: 0.06334653070560711\n",
      "Epoch 950/1000, Loss: 0.06334660867646877\n",
      "Epoch 960/1000, Loss: 0.06334903855274025\n",
      "Epoch 970/1000, Loss: 0.06350238045464547\n",
      "Epoch 980/1000, Loss: 0.06338048464793972\n",
      "Epoch 990/1000, Loss: 0.06336541373104553\n",
      "Epoch 1000/1000, Loss: 0.06335343678683496\n",
      "Maximum absolute weight: 0.5965650803062462\n",
      "\n",
      "---------- finished run ----------\n",
      "9\n",
      "Epoch 10/1000, Loss: 0.11935207815504202\n",
      "Epoch 20/1000, Loss: 0.11900098785240988\n",
      "Epoch 30/1000, Loss: 0.11334558396058554\n",
      "Epoch 40/1000, Loss: 0.10332523954435567\n",
      "Epoch 50/1000, Loss: 0.07942876523688942\n",
      "Epoch 60/1000, Loss: 0.0012535542968478686\n",
      "Epoch 70/1000, Loss: 0.003715461064981371\n",
      "Epoch 80/1000, Loss: 0.002049120947313585\n",
      "Epoch 90/1000, Loss: 0.0010921124811315293\n",
      "Epoch 100/1000, Loss: 0.0005426145714056725\n",
      "Epoch 110/1000, Loss: 0.0003540142780347414\n",
      "Epoch 120/1000, Loss: 0.00025269380614936646\n",
      "Epoch 130/1000, Loss: 0.0001724093990448306\n",
      "Epoch 140/1000, Loss: 0.0001406592184305471\n",
      "Epoch 150/1000, Loss: 0.00011563403177958894\n",
      "Epoch 160/1000, Loss: 9.662113361098482e-05\n",
      "Epoch 170/1000, Loss: 8.154688999653394e-05\n",
      "Epoch 180/1000, Loss: 7.01838695846609e-05\n",
      "Epoch 190/1000, Loss: 6.14649030250816e-05\n",
      "Epoch 200/1000, Loss: 5.5353810867353694e-05\n",
      "Epoch 210/1000, Loss: 5.0516189936046534e-05\n",
      "Epoch 220/1000, Loss: 4.6450676933881675e-05\n",
      "Epoch 230/1000, Loss: 4.296978131123906e-05\n",
      "Epoch 240/1000, Loss: 3.999085302158206e-05\n",
      "Epoch 250/1000, Loss: 3.750003322247098e-05\n",
      "Epoch 260/1000, Loss: 3.537534495072879e-05\n",
      "Epoch 270/1000, Loss: 3.3648347164156364e-05\n",
      "Epoch 280/1000, Loss: 3.2123533895953446e-05\n",
      "Epoch 290/1000, Loss: 3.078777630150592e-05\n",
      "Epoch 300/1000, Loss: 2.9491393274130583e-05\n",
      "Epoch 310/1000, Loss: 2.8241993466209898e-05\n",
      "Epoch 320/1000, Loss: 2.702950377912384e-05\n",
      "Epoch 330/1000, Loss: 2.591928775919333e-05\n",
      "Epoch 340/1000, Loss: 2.4882250297666006e-05\n",
      "Epoch 350/1000, Loss: 2.3888435945718874e-05\n",
      "Epoch 360/1000, Loss: 2.2927235186097383e-05\n",
      "Epoch 370/1000, Loss: 2.1828308349509942e-05\n",
      "Epoch 380/1000, Loss: 2.065239408266149e-05\n",
      "Epoch 390/1000, Loss: 1.916724788659314e-05\n",
      "Epoch 400/1000, Loss: 1.7341669600677323e-05\n",
      "Epoch 410/1000, Loss: 5.443732105412538e-05\n",
      "Epoch 420/1000, Loss: 4.853339809493337e-05\n",
      "Epoch 430/1000, Loss: 2.643440165912318e-05\n",
      "Epoch 440/1000, Loss: 1.2254915784681232e-05\n",
      "Epoch 450/1000, Loss: 2.885320104671181e-05\n",
      "Epoch 460/1000, Loss: 5.2863219678798276e-05\n",
      "Epoch 470/1000, Loss: 1.1336013703849707e-05\n",
      "Epoch 480/1000, Loss: 2.7889055315388568e-05\n",
      "Epoch 490/1000, Loss: 2.8003155896512133e-05\n",
      "Epoch 500/1000, Loss: 1.83742633535205e-05\n",
      "Epoch 510/1000, Loss: 1.1122847974904497e-05\n",
      "Epoch 520/1000, Loss: 9.991344830394006e-06\n",
      "Epoch 530/1000, Loss: 1.4340057801530868e-05\n",
      "Epoch 540/1000, Loss: 7.405701484486694e-06\n",
      "Epoch 550/1000, Loss: 7.35238689262565e-06\n",
      "Epoch 560/1000, Loss: 0.00021272377706064307\n",
      "Epoch 570/1000, Loss: 0.00022901202341415097\n",
      "Epoch 580/1000, Loss: 9.096780269600514e-06\n",
      "Epoch 590/1000, Loss: 3.0551597562025665e-05\n",
      "Epoch 600/1000, Loss: 2.0380161493550135e-05\n",
      "Epoch 610/1000, Loss: 1.3863377599018123e-05\n",
      "Epoch 620/1000, Loss: 7.066639388114809e-06\n",
      "Epoch 630/1000, Loss: 6.343316886798948e-06\n",
      "Epoch 640/1000, Loss: 7.874124604249603e-05\n",
      "Epoch 650/1000, Loss: 4.7665234310932214e-05\n",
      "Epoch 660/1000, Loss: 7.492657990188379e-05\n",
      "Epoch 670/1000, Loss: 4.63156061894687e-05\n",
      "Epoch 680/1000, Loss: 2.2976845619398616e-05\n",
      "Epoch 690/1000, Loss: 1.4017860030155277e-05\n",
      "Epoch 700/1000, Loss: 6.143032190742331e-06\n",
      "Epoch 710/1000, Loss: 4.830828858708529e-06\n",
      "Epoch 720/1000, Loss: 4.700600412403293e-06\n",
      "Epoch 730/1000, Loss: 4.9013201061007e-05\n",
      "Epoch 740/1000, Loss: 0.0002714293974112\n",
      "Epoch 750/1000, Loss: 1.8714777462601982e-05\n",
      "Epoch 760/1000, Loss: 1.0442713946959021e-05\n",
      "Epoch 770/1000, Loss: 1.3722609203631785e-05\n",
      "Epoch 780/1000, Loss: 1.4047567484336379e-05\n",
      "Epoch 790/1000, Loss: 7.083994877832651e-06\n",
      "Epoch 800/1000, Loss: 4.945058965707036e-06\n",
      "Epoch 810/1000, Loss: 4.541945397125529e-06\n",
      "Epoch 820/1000, Loss: 4.621328913348863e-06\n",
      "Epoch 830/1000, Loss: 4.542254455028603e-06\n",
      "Epoch 840/1000, Loss: 1.8216153252336026e-05\n",
      "Epoch 850/1000, Loss: 0.0001552997114977912\n",
      "Epoch 860/1000, Loss: 0.00011624629907911397\n",
      "Epoch 870/1000, Loss: 2.7595795324980298e-05\n",
      "Epoch 880/1000, Loss: 1.5666749856004372e-05\n",
      "Epoch 890/1000, Loss: 1.6352671678777903e-05\n",
      "Epoch 900/1000, Loss: 4.82374673291711e-06\n",
      "Epoch 910/1000, Loss: 2.908508943053076e-05\n",
      "Epoch 920/1000, Loss: 9.456450976970934e-05\n",
      "Epoch 930/1000, Loss: 5.931348711140939e-05\n",
      "Epoch 940/1000, Loss: 9.126193278186298e-06\n",
      "Epoch 950/1000, Loss: 3.468937752567292e-05\n",
      "Epoch 960/1000, Loss: 3.6828303438451504e-05\n",
      "Epoch 970/1000, Loss: 4.885244240467818e-06\n",
      "Epoch 980/1000, Loss: 4.0220958410144044e-05\n",
      "Epoch 990/1000, Loss: 2.8980089894673987e-05\n",
      "Epoch 1000/1000, Loss: 4.390777621431835e-06\n",
      "Maximum absolute weight: 0.7821117313815268\n",
      "\n",
      "---------- finished run ----------\n"
     ]
    }
   ],
   "source": [
    "N_models=10\n",
    "data_32=np.zeros((len(DMRG64[\"p\"]),N_models))\n",
    "data_64=np.zeros((len(DMRG64[\"p\"]),N_models))\n",
    "training_fail=[]\n",
    "for i in range(N_models):\n",
    "    print(i)\n",
    "    model = Net()\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.002)\n",
    "   \n",
    "\n",
    "\n",
    "    epochs = 1000\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        outputs = model(X_train_tensor)\n",
    "        alpha = 0\n",
    "        loss_mse = criterion(outputs, y_train_tensor)\n",
    "        loss=loss_mse\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():}\")\n",
    "    if loss.item()>1e-3:\n",
    "        training_fail.append(i)\n",
    "            \n",
    "    max_abs_weight = max(param.abs().max().item() for param in model.parameters() if param.requires_grad)\n",
    "\n",
    "    print(\"Maximum absolute weight:\", max_abs_weight)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        results32 = model(X_prediction_tensor_32)\n",
    "        results64 = model(X_prediction_tensor_64)\n",
    "        data_32[:,i]=results32[:,0]\n",
    "        data_64[:,i]=results64[:,0]\n",
    "    print()\n",
    "    print(\"---------- finished run ----------\")\n",
    "results32=data_32.mean(axis=1)\n",
    "results64=data_64.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4839214a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name=\"..\\\\data\\\\correlators_Z2\\\\Fidelity_L32_L64.csv\"\n",
    "data = {\n",
    "\"Fidelity_L32\": results32[:,0],\n",
    "\"Fidelity_L64\": results64[:,0],\n",
    "\"p\": DMRG32[\"p\"]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sw-ssb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
